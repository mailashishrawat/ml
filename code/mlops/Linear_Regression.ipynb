{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVoY6ZChDrc5"
   },
   "source": [
    "# **Google Colab**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPDKVoEDCAbF"
   },
   "source": [
    "This service is hosted on a virtual machine (vm). This vm is a linux vm and hence can run all linux commands directly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1045,
     "status": "ok",
     "timestamp": 1604328637636,
     "user": {
      "displayName": "Naveen Colab",
      "photoUrl": "",
      "userId": "15626251679927899334"
     },
     "user_tz": -330
    },
    "id": "FDR0Mw-2CJTS",
    "outputId": "cc218295-903f-4f3a-af4e-d219902b4723"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear_Regression.ipynb  bentofile.yaml           reinforcement.ipynb\n",
      "Model_Consumer.ipynb     mlops.ipynb\n",
      "Model_Container.ipynb    prescriptive.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls   # List the files and folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1159,
     "status": "ok",
     "timestamp": 1604328638582,
     "user": {
      "displayName": "Naveen Colab",
      "photoUrl": "",
      "userId": "15626251679927899334"
     },
     "user_tz": -330
    },
    "id": "-h-Dx5LTCqOC"
   },
   "outputs": [],
   "source": [
    "mkdir temp # This creates a folder called temp and which can viewed in the Files section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1158,
     "status": "ok",
     "timestamp": 1604328625901,
     "user": {
      "displayName": "Naveen Colab",
      "photoUrl": "",
      "userId": "15626251679927899334"
     },
     "user_tz": -330
    },
    "id": "GRUBF84_Fn0n",
    "outputId": "1916000b-783c-440b-f38d-0cd685414b6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear_Regression.ipynb  bentofile.yaml           reinforcement.ipynb\n",
      "Model_Consumer.ipynb     mlops.ipynb              \u001b[34mtemp\u001b[m\u001b[m/\n",
      "Model_Container.ipynb    prescriptive.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3wHW_-A7_C_"
   },
   "source": [
    "# **Linear Regression**\n",
    "\n",
    "Let us run through a simple machine learning code.\n",
    "\n",
    "By default, the run time type would be None i.e. CPU. We shall let it be for this exercise, as we do not have code which would need GPUs or TPUs, which will come up though when we run deep learning coding exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbTdROIM8Ehp"
   },
   "source": [
    "## Creating Dataset\n",
    "\n",
    "We can upload the data files to the vm using the UI from Files section \n",
    "\n",
    "OR\n",
    "\n",
    "Mount the Google Drive to access the files placed there.\n",
    "\n",
    "However, to keep it simple, let us create a dataset for linear regression using the scikit-learn package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoAQ5vLdEHHm"
   },
   "source": [
    "This environment has lots of data science, machine learning and deep learning related libraries such as numpy, pandas, scikit-learn, keras, tensorflow etc. pre-installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1836,
     "status": "ok",
     "timestamp": 1604328644994,
     "user": {
      "displayName": "Naveen Colab",
      "photoUrl": "",
      "userId": "15626251679927899334"
     },
     "user_tz": -330
    },
    "id": "EjG0goIx7T69"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1244,
     "status": "ok",
     "timestamp": 1604328644995,
     "user": {
      "displayName": "Naveen Colab",
      "photoUrl": "",
      "userId": "15626251679927899334"
     },
     "user_tz": -330
    },
    "id": "MkXE4fQlnifO"
   },
   "outputs": [],
   "source": [
    "# This creates a dataset of 10000 observations.\n",
    "X, y = make_regression(n_samples=10000, noise=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "executionInfo": {
     "elapsed": 908,
     "status": "ok",
     "timestamp": 1604328645340,
     "user": {
      "displayName": "Naveen Colab",
      "photoUrl": "",
      "userId": "15626251679927899334"
     },
     "user_tz": -330
    },
    "id": "8MkdtmvlJeOw",
    "outputId": "08d0e66d-e31e-464a-ec49-7f5c49b87e32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.382091</td>\n",
       "      <td>0.430939</td>\n",
       "      <td>0.682143</td>\n",
       "      <td>2.232057</td>\n",
       "      <td>0.802403</td>\n",
       "      <td>0.369829</td>\n",
       "      <td>0.642973</td>\n",
       "      <td>-2.849005</td>\n",
       "      <td>-0.419511</td>\n",
       "      <td>0.159887</td>\n",
       "      <td>...</td>\n",
       "      <td>1.047080</td>\n",
       "      <td>1.703108</td>\n",
       "      <td>0.541138</td>\n",
       "      <td>-0.833509</td>\n",
       "      <td>0.569558</td>\n",
       "      <td>1.539171</td>\n",
       "      <td>-1.128982</td>\n",
       "      <td>0.514039</td>\n",
       "      <td>-2.243071</td>\n",
       "      <td>-1.135817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.825349</td>\n",
       "      <td>0.067969</td>\n",
       "      <td>2.330280</td>\n",
       "      <td>1.457144</td>\n",
       "      <td>0.510453</td>\n",
       "      <td>0.032072</td>\n",
       "      <td>0.652267</td>\n",
       "      <td>-0.815316</td>\n",
       "      <td>-0.453352</td>\n",
       "      <td>0.909625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742098</td>\n",
       "      <td>-1.243687</td>\n",
       "      <td>0.704945</td>\n",
       "      <td>-1.099195</td>\n",
       "      <td>0.198444</td>\n",
       "      <td>-1.462778</td>\n",
       "      <td>1.002992</td>\n",
       "      <td>1.024173</td>\n",
       "      <td>-1.270950</td>\n",
       "      <td>-0.813493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.306427</td>\n",
       "      <td>-0.238174</td>\n",
       "      <td>0.710810</td>\n",
       "      <td>1.464507</td>\n",
       "      <td>0.054563</td>\n",
       "      <td>0.407808</td>\n",
       "      <td>-0.125505</td>\n",
       "      <td>-0.240433</td>\n",
       "      <td>0.390337</td>\n",
       "      <td>-0.855007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.754053</td>\n",
       "      <td>-0.795787</td>\n",
       "      <td>-0.191319</td>\n",
       "      <td>-2.669837</td>\n",
       "      <td>0.647410</td>\n",
       "      <td>1.030503</td>\n",
       "      <td>-0.224763</td>\n",
       "      <td>1.510323</td>\n",
       "      <td>0.954053</td>\n",
       "      <td>-0.919152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.986578</td>\n",
       "      <td>-0.386535</td>\n",
       "      <td>0.481427</td>\n",
       "      <td>-0.394058</td>\n",
       "      <td>0.666178</td>\n",
       "      <td>-1.745712</td>\n",
       "      <td>-0.189805</td>\n",
       "      <td>0.177207</td>\n",
       "      <td>-0.439799</td>\n",
       "      <td>0.269517</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.588792</td>\n",
       "      <td>-0.121647</td>\n",
       "      <td>1.218384</td>\n",
       "      <td>-1.447856</td>\n",
       "      <td>1.980360</td>\n",
       "      <td>-1.343717</td>\n",
       "      <td>0.283788</td>\n",
       "      <td>-0.806967</td>\n",
       "      <td>1.130067</td>\n",
       "      <td>2.011601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.414273</td>\n",
       "      <td>-0.258854</td>\n",
       "      <td>2.284059</td>\n",
       "      <td>1.366691</td>\n",
       "      <td>1.245642</td>\n",
       "      <td>-0.934696</td>\n",
       "      <td>0.689684</td>\n",
       "      <td>0.061712</td>\n",
       "      <td>-0.616612</td>\n",
       "      <td>-1.106555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.571933</td>\n",
       "      <td>-0.989417</td>\n",
       "      <td>-2.840105</td>\n",
       "      <td>1.107784</td>\n",
       "      <td>-1.212801</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>0.616329</td>\n",
       "      <td>0.497136</td>\n",
       "      <td>0.836949</td>\n",
       "      <td>-0.333378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.137959</td>\n",
       "      <td>-0.386527</td>\n",
       "      <td>-0.819346</td>\n",
       "      <td>-0.749804</td>\n",
       "      <td>0.152594</td>\n",
       "      <td>0.754791</td>\n",
       "      <td>-0.181395</td>\n",
       "      <td>1.031959</td>\n",
       "      <td>-0.346110</td>\n",
       "      <td>-1.540971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.628448</td>\n",
       "      <td>-0.049633</td>\n",
       "      <td>-1.164040</td>\n",
       "      <td>-1.959131</td>\n",
       "      <td>0.493298</td>\n",
       "      <td>0.965751</td>\n",
       "      <td>0.989401</td>\n",
       "      <td>-1.093455</td>\n",
       "      <td>-0.477840</td>\n",
       "      <td>0.414531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-0.161342</td>\n",
       "      <td>-1.227539</td>\n",
       "      <td>0.295063</td>\n",
       "      <td>1.939446</td>\n",
       "      <td>-0.811173</td>\n",
       "      <td>-1.384774</td>\n",
       "      <td>-0.289315</td>\n",
       "      <td>-0.979528</td>\n",
       "      <td>1.886022</td>\n",
       "      <td>1.529358</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051779</td>\n",
       "      <td>-0.920339</td>\n",
       "      <td>0.713495</td>\n",
       "      <td>0.408467</td>\n",
       "      <td>-1.293508</td>\n",
       "      <td>-0.404184</td>\n",
       "      <td>-1.776082</td>\n",
       "      <td>0.195594</td>\n",
       "      <td>0.713680</td>\n",
       "      <td>-0.481305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.091834</td>\n",
       "      <td>-0.738803</td>\n",
       "      <td>-0.146753</td>\n",
       "      <td>-0.461468</td>\n",
       "      <td>0.843328</td>\n",
       "      <td>-1.043127</td>\n",
       "      <td>-0.154017</td>\n",
       "      <td>0.329115</td>\n",
       "      <td>-1.109591</td>\n",
       "      <td>0.538544</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.384460</td>\n",
       "      <td>0.409989</td>\n",
       "      <td>1.025547</td>\n",
       "      <td>0.030234</td>\n",
       "      <td>0.635381</td>\n",
       "      <td>-0.172642</td>\n",
       "      <td>0.500108</td>\n",
       "      <td>1.886333</td>\n",
       "      <td>-0.104066</td>\n",
       "      <td>-1.201743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-1.150263</td>\n",
       "      <td>0.467451</td>\n",
       "      <td>-0.428100</td>\n",
       "      <td>0.070136</td>\n",
       "      <td>3.064479</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>-0.072057</td>\n",
       "      <td>1.405337</td>\n",
       "      <td>-1.614943</td>\n",
       "      <td>-1.623611</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154872</td>\n",
       "      <td>-1.277395</td>\n",
       "      <td>1.177093</td>\n",
       "      <td>-0.724594</td>\n",
       "      <td>1.415416</td>\n",
       "      <td>0.007130</td>\n",
       "      <td>-0.853168</td>\n",
       "      <td>-1.238477</td>\n",
       "      <td>1.076765</td>\n",
       "      <td>-1.938247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.066207</td>\n",
       "      <td>2.634938</td>\n",
       "      <td>-1.930203</td>\n",
       "      <td>-0.373079</td>\n",
       "      <td>0.145692</td>\n",
       "      <td>-0.420337</td>\n",
       "      <td>-0.518345</td>\n",
       "      <td>0.300569</td>\n",
       "      <td>-0.873764</td>\n",
       "      <td>0.371578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.788873</td>\n",
       "      <td>0.143941</td>\n",
       "      <td>0.391366</td>\n",
       "      <td>-0.357559</td>\n",
       "      <td>-1.853253</td>\n",
       "      <td>0.902161</td>\n",
       "      <td>0.054471</td>\n",
       "      <td>1.303002</td>\n",
       "      <td>-0.065905</td>\n",
       "      <td>2.004215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -1.382091  0.430939  0.682143  2.232057  0.802403  0.369829  0.642973   \n",
       "1     0.825349  0.067969  2.330280  1.457144  0.510453  0.032072  0.652267   \n",
       "2     1.306427 -0.238174  0.710810  1.464507  0.054563  0.407808 -0.125505   \n",
       "3     0.986578 -0.386535  0.481427 -0.394058  0.666178 -1.745712 -0.189805   \n",
       "4    -1.414273 -0.258854  2.284059  1.366691  1.245642 -0.934696  0.689684   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  0.137959 -0.386527 -0.819346 -0.749804  0.152594  0.754791 -0.181395   \n",
       "9996 -0.161342 -1.227539  0.295063  1.939446 -0.811173 -1.384774 -0.289315   \n",
       "9997  1.091834 -0.738803 -0.146753 -0.461468  0.843328 -1.043127 -0.154017   \n",
       "9998 -1.150263  0.467451 -0.428100  0.070136  3.064479  0.050654 -0.072057   \n",
       "9999  0.066207  2.634938 -1.930203 -0.373079  0.145692 -0.420337 -0.518345   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "0    -2.849005 -0.419511  0.159887  ...  1.047080  1.703108  0.541138   \n",
       "1    -0.815316 -0.453352  0.909625  ...  0.742098 -1.243687  0.704945   \n",
       "2    -0.240433  0.390337 -0.855007  ... -0.754053 -0.795787 -0.191319   \n",
       "3     0.177207 -0.439799  0.269517  ... -1.588792 -0.121647  1.218384   \n",
       "4     0.061712 -0.616612 -1.106555  ... -0.571933 -0.989417 -2.840105   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  1.031959 -0.346110 -1.540971  ... -0.628448 -0.049633 -1.164040   \n",
       "9996 -0.979528  1.886022  1.529358  ...  1.051779 -0.920339  0.713495   \n",
       "9997  0.329115 -1.109591  0.538544  ... -1.384460  0.409989  1.025547   \n",
       "9998  1.405337 -1.614943 -1.623611  ... -0.154872 -1.277395  1.177093   \n",
       "9999  0.300569 -0.873764  0.371578  ... -0.788873  0.143941  0.391366   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "0    -0.833509  0.569558  1.539171 -1.128982  0.514039 -2.243071 -1.135817  \n",
       "1    -1.099195  0.198444 -1.462778  1.002992  1.024173 -1.270950 -0.813493  \n",
       "2    -2.669837  0.647410  1.030503 -0.224763  1.510323  0.954053 -0.919152  \n",
       "3    -1.447856  1.980360 -1.343717  0.283788 -0.806967  1.130067  2.011601  \n",
       "4     1.107784 -1.212801  0.010032  0.616329  0.497136  0.836949 -0.333378  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "9995 -1.959131  0.493298  0.965751  0.989401 -1.093455 -0.477840  0.414531  \n",
       "9996  0.408467 -1.293508 -0.404184 -1.776082  0.195594  0.713680 -0.481305  \n",
       "9997  0.030234  0.635381 -0.172642  0.500108  1.886333 -0.104066 -1.201743  \n",
       "9998 -0.724594  1.415416  0.007130 -0.853168 -1.238477  1.076765 -1.938247  \n",
       "9999 -0.357559 -1.853253  0.902161  0.054471  1.303002 -0.065905  2.004215  \n",
       "\n",
       "[10000 rows x 100 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(X)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rn_HWnMDJtJn"
   },
   "source": [
    "**So, we see that we have 10000 observations and each observation has 100 independent variables.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0a8Mj9S77RZ"
   },
   "source": [
    "## Split dataset into training and validation dataset.\n",
    "\n",
    "And like in any machine learning project, let us split the dataset into training and validation dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1604328647137,
     "user": {
      "displayName": "Naveen Colab",
      "photoUrl": "",
      "userId": "15626251679927899334"
     },
     "user_tz": -330
    },
    "id": "XEEPAOLR7b4S"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1344,
     "status": "ok",
     "timestamp": 1604328648253,
     "user": {
      "displayName": "Naveen Colab",
      "photoUrl": "",
      "userId": "15626251679927899334"
     },
     "user_tz": -330
    },
    "id": "jpXCmqrZ7Vr8"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsIxrEGg-vyE"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1125,
     "status": "ok",
     "timestamp": 1604328648818,
     "user": {
      "displayName": "Naveen Colab",
      "photoUrl": "",
      "userId": "15626251679927899334"
     },
     "user_tz": -330
    },
    "id": "LbmBVcM6-u7m"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 816,
     "status": "ok",
     "timestamp": 1604328649153,
     "user": {
      "displayName": "Naveen Colab",
      "photoUrl": "",
      "userId": "15626251679927899334"
     },
     "user_tz": -330
    },
    "id": "LasfIJ3e_vzO",
    "outputId": "185997e8-d299-43a2-d7e8-99b4635921c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = LinearRegression()\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNNKjPV1_d2a"
   },
   "source": [
    "## Model Prediction\n",
    "\n",
    "Let us use the model to predict on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 946,
     "status": "ok",
     "timestamp": 1604328650857,
     "user": {
      "displayName": "Naveen Colab",
      "photoUrl": "",
      "userId": "15626251679927899334"
     },
     "user_tz": -330
    },
    "id": "mRYVWnvO_dFD",
    "outputId": "25c9ea48-b06d-4592-efdc-14e5bb4f76ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 226.28136956,  195.8050956 , -142.15789352, ..., -297.06624593,\n",
       "       -232.29689361,   45.49581835])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rym_TWzsGYxS"
   },
   "source": [
    "Well, that was pretty straight forward.\n",
    "\n",
    "One of the advantages of using this environment is that it is great for colloboration as the environments would not differ. If you make sure that that scripts run at your end, it would work quite smoothly in anyone's colab environment without worrying about their environment configuration."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO9O5fVMtPd1bcUcTUxceGY",
   "collapsed_sections": [],
   "name": "Linear_Regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
